{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9666470,"sourceType":"datasetVersion","datasetId":5280858}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# !pip install git+https://github.com/openai/whisper.git","metadata":{"execution":{"iopub.status.busy":"2024-10-24T08:43:34.730904Z","iopub.execute_input":"2024-10-24T08:43:34.731160Z","iopub.status.idle":"2024-10-24T08:43:34.735806Z","shell.execute_reply.started":"2024-10-24T08:43:34.731136Z","shell.execute_reply":"2024-10-24T08:43:34.734915Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import os\nimport time\nimport pandas as pd\nimport torch\nfrom transformers import pipeline","metadata":{"execution":{"iopub.status.busy":"2024-10-24T08:43:34.737427Z","iopub.execute_input":"2024-10-24T08:43:34.738065Z","iopub.status.idle":"2024-10-24T08:43:55.125740Z","shell.execute_reply.started":"2024-10-24T08:43:34.738040Z","shell.execute_reply":"2024-10-24T08:43:55.124788Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-10-24 08:43:42.592831: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-10-24 08:43:42.592965: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-10-24 08:43:42.729923: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"# all files without 6 and 7 (they are too long)\nfiles_directory = '/kaggle/input/speech-to-text/'\n\naudio_files_for_transcribtion = [file for file in os.listdir(files_directory)\n                                 if file.startswith('sample') and 'out' not in file ]\n\naudio_files_for_transcribtion.remove('sample4.mp3')\naudio_files_for_transcribtion.remove('sample7.mp3')\n\naudio_files_for_transcribtion.sort( key=lambda x:int(\"\".join(filter(str.isdigit,x))))\naudio_files_for_transcribtion","metadata":{"execution":{"iopub.status.busy":"2024-10-24T08:43:55.127365Z","iopub.execute_input":"2024-10-24T08:43:55.127916Z","iopub.status.idle":"2024-10-24T08:43:55.153239Z","shell.execute_reply.started":"2024-10-24T08:43:55.127889Z","shell.execute_reply":"2024-10-24T08:43:55.152320Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"['sample1.mp3',\n 'sample2.mp3',\n 'sample3.mp3',\n 'sample8.mp3',\n 'sample9.mp3',\n 'sample10.mp3',\n 'sample11.mp3',\n 'sample12.mp3',\n 'sample13.mp3',\n 'sample14.mp3',\n 'sample15.mp3']"},"metadata":{}}]},{"cell_type":"markdown","source":"# ivrit","metadata":{}},{"cell_type":"code","source":"#model_nm = 'ivrit-ai/whisper-13-v2-e3'\nmodel_nm = \"ivrit-ai/whisper-large-v2-tuned\"","metadata":{"execution":{"iopub.status.busy":"2024-10-24T08:43:55.160580Z","iopub.execute_input":"2024-10-24T08:43:55.160978Z","iopub.status.idle":"2024-10-24T08:43:55.167864Z","shell.execute_reply.started":"2024-10-24T08:43:55.160948Z","shell.execute_reply":"2024-10-24T08:43:55.167115Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"\n\ndevice = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n\npipe = pipeline(\n  \"automatic-speech-recognition\",\n  model= model_nm,\n  chunk_length_s=30,\n  batch_size=8,\n  device=device,\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-24T08:53:11.810173Z","iopub.execute_input":"2024-10-24T08:53:11.810910Z","iopub.status.idle":"2024-10-24T08:53:15.967941Z","shell.execute_reply.started":"2024-10-24T08:53:11.810879Z","shell.execute_reply":"2024-10-24T08:53:15.967045Z"},"trusted":true},"execution_count":24,"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"34129ee1b4f541a18fe24d80fe6cf56a"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\nSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}]},{"cell_type":"code","source":"audio_file_path = '/kaggle/input/speech-to-text/sample8.mp3'","metadata":{"execution":{"iopub.status.busy":"2024-10-24T08:53:15.969741Z","iopub.execute_input":"2024-10-24T08:53:15.970049Z","iopub.status.idle":"2024-10-24T08:53:15.973990Z","shell.execute_reply.started":"2024-10-24T08:53:15.970023Z","shell.execute_reply":"2024-10-24T08:53:15.973105Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"%%time\nprediction = pipe(audio_file_path, generate_kwargs={\"language\": \"hebrew\"})[\"text\"]","metadata":{"execution":{"iopub.status.busy":"2024-10-24T08:53:15.975160Z","iopub.execute_input":"2024-10-24T08:53:15.975570Z","iopub.status.idle":"2024-10-24T08:53:24.921005Z","shell.execute_reply.started":"2024-10-24T08:53:15.975541Z","shell.execute_reply":"2024-10-24T08:53:24.920023Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"CPU times: user 8.82 s, sys: 15.5 ms, total: 8.83 s\nWall time: 8.94 s\n","output_type":"stream"}]},{"cell_type":"code","source":"prediction","metadata":{"execution":{"iopub.status.busy":"2024-10-24T08:48:52.509205Z","iopub.execute_input":"2024-10-24T08:48:52.509609Z","iopub.status.idle":"2024-10-24T08:48:52.515658Z","shell.execute_reply.started":"2024-10-24T08:48:52.509581Z","shell.execute_reply":"2024-10-24T08:48:52.514821Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"'הלו, עוזי? כן? חברת טוט, מה קורה? בסדר יופי, מתקשרת לגבי הצעות מחיר איפה אתה נמצא היום באינטה ובביתי? בשבילכם בסלולר לא, לא רלוונטי, תודה למה לא רלוונטי? לא רלוונטי, לא רלוונטי, תודה מה לא רלוונטי? אין לך סלולר? לא רלוונטי, נשמה, לא רלוונטי מה זה לא רלוונטי? אין לך סלולר? אני חייבת להבין מה זה התשובה הזאתי שלך מה, את רצינית איתי? מה זה לא רלוונטי, אין לך סלולר... אני אומר לך שלא רלוונטי מה שאת מציעה לי לא רלוונטי, חינם, חינם, לא רלוונטי אבל עוד לא שמעת אותי אבל הנה, תגיד לי, חינם, קח טלפון חינם, אל תגיד לי לא רלוונטי אני אגיד לך חינם, אין דבר כזה חינם אז זה לא רלוונטי אני אומר לך, מה את רווייתי? אבל עוד לא שמעת, זה חטא'"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"d = []\nfor i,f in enumerate(audio_files_for_transcribtion):\n    print(i, end='')\n    start = time.time()\n    text = pipe(files_directory+f, generate_kwargs={\"language\": \"hebrew\"})[\"text\"]\n    end = time.time()\n    d.append(\n        {\n            'name':f,\n            'text':text,\n            'run_time':end - start,\n            'engine':torch.cuda.get_device_name()\n  \n                    }\n    )\n\nresults = pd.DataFrame(d)\nresults","metadata":{"execution":{"iopub.status.busy":"2024-10-23T17:00:35.849302Z","iopub.execute_input":"2024-10-23T17:00:35.849563Z","iopub.status.idle":"2024-10-23T17:03:36.612667Z","shell.execute_reply.started":"2024-10-23T17:00:35.849541Z","shell.execute_reply":"2024-10-23T17:03:36.611765Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"0123456789","output_type":"stream"},{"name":"stderr","text":"You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","output_type":"stream"},{"name":"stdout","text":"10","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"            name                                               text  \\\n0    sample1.mp3  הלו שלום היי שלום, שנייה הלו שלום הלו, מי אני ...   \n1    sample2.mp3  היי רותי, רועי מראל, מה הביטוח שלכם, מה שלומך?...   \n2    sample3.mp3  שלום, ותודה שתניתם לכולם. מקומכם בתור הינו, אח...   \n3    sample8.mp3  הלו, עוזי? כן? חברת טוט, מה קורה? בסדר יופי, מ...   \n4    sample9.mp3  הלו? שלום. כן, שלום. אני מפרק, מה אתה רואה? אה...   \n5   sample10.mp3  אבל כן, אבל המהירות גלישה שלנו הרבה יותר גבוהה...   \n6   sample11.mp3  שלום אלון, נכון, שלום לך, מדבר את ורד מאיחוד מ...   \n7   sample12.mp3  פלקום שלום, תודה על ההמתנה. בוקר טוב. בוקר מצו...   \n8   sample13.mp3  בסדרוהחלפת נורא שנשרפה בעלות הנורא בלבד. כן, פ...   \n9   sample14.mp3  הלו? כן, שלום. שלום, אני מתקשרת בקשר למודעה שר...   \n10  sample15.mp3  שלום ותודה שהתקשרתם, ביאבנאנה שלום, מדבר את שו...   \n\n     run_time    engine  \n0   16.123071  Tesla T4  \n1   12.014237  Tesla T4  \n2   20.412798  Tesla T4  \n3    8.944068  Tesla T4  \n4    6.888821  Tesla T4  \n5   21.519279  Tesla T4  \n6   15.400238  Tesla T4  \n7   27.975692  Tesla T4  \n8    9.820299  Tesla T4  \n9   26.842724  Tesla T4  \n10  13.895736  Tesla T4  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>text</th>\n      <th>run_time</th>\n      <th>engine</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>sample1.mp3</td>\n      <td>הלו שלום היי שלום, שנייה הלו שלום הלו, מי אני ...</td>\n      <td>16.123071</td>\n      <td>Tesla T4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>sample2.mp3</td>\n      <td>היי רותי, רועי מראל, מה הביטוח שלכם, מה שלומך?...</td>\n      <td>12.014237</td>\n      <td>Tesla T4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>sample3.mp3</td>\n      <td>שלום, ותודה שתניתם לכולם. מקומכם בתור הינו, אח...</td>\n      <td>20.412798</td>\n      <td>Tesla T4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>sample8.mp3</td>\n      <td>הלו, עוזי? כן? חברת טוט, מה קורה? בסדר יופי, מ...</td>\n      <td>8.944068</td>\n      <td>Tesla T4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>sample9.mp3</td>\n      <td>הלו? שלום. כן, שלום. אני מפרק, מה אתה רואה? אה...</td>\n      <td>6.888821</td>\n      <td>Tesla T4</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>sample10.mp3</td>\n      <td>אבל כן, אבל המהירות גלישה שלנו הרבה יותר גבוהה...</td>\n      <td>21.519279</td>\n      <td>Tesla T4</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>sample11.mp3</td>\n      <td>שלום אלון, נכון, שלום לך, מדבר את ורד מאיחוד מ...</td>\n      <td>15.400238</td>\n      <td>Tesla T4</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>sample12.mp3</td>\n      <td>פלקום שלום, תודה על ההמתנה. בוקר טוב. בוקר מצו...</td>\n      <td>27.975692</td>\n      <td>Tesla T4</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>sample13.mp3</td>\n      <td>בסדרוהחלפת נורא שנשרפה בעלות הנורא בלבד. כן, פ...</td>\n      <td>9.820299</td>\n      <td>Tesla T4</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>sample14.mp3</td>\n      <td>הלו? כן, שלום. שלום, אני מתקשרת בקשר למודעה שר...</td>\n      <td>26.842724</td>\n      <td>Tesla T4</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>sample15.mp3</td>\n      <td>שלום ותודה שהתקשרתם, ביאבנאנה שלום, מדבר את שו...</td>\n      <td>13.895736</td>\n      <td>Tesla T4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"results['text_length'] = results['text'].str.len()\nresults['model'] = model_nm\nresults","metadata":{"execution":{"iopub.status.busy":"2024-10-23T17:03:36.613883Z","iopub.execute_input":"2024-10-23T17:03:36.614266Z","iopub.status.idle":"2024-10-23T17:03:36.630174Z","shell.execute_reply.started":"2024-10-23T17:03:36.614224Z","shell.execute_reply":"2024-10-23T17:03:36.629123Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"            name                                               text  \\\n0    sample1.mp3  הלו שלום היי שלום, שנייה הלו שלום הלו, מי אני ...   \n1    sample2.mp3  היי רותי, רועי מראל, מה הביטוח שלכם, מה שלומך?...   \n2    sample3.mp3  שלום, ותודה שתניתם לכולם. מקומכם בתור הינו, אח...   \n3    sample8.mp3  הלו, עוזי? כן? חברת טוט, מה קורה? בסדר יופי, מ...   \n4    sample9.mp3  הלו? שלום. כן, שלום. אני מפרק, מה אתה רואה? אה...   \n5   sample10.mp3  אבל כן, אבל המהירות גלישה שלנו הרבה יותר גבוהה...   \n6   sample11.mp3  שלום אלון, נכון, שלום לך, מדבר את ורד מאיחוד מ...   \n7   sample12.mp3  פלקום שלום, תודה על ההמתנה. בוקר טוב. בוקר מצו...   \n8   sample13.mp3  בסדרוהחלפת נורא שנשרפה בעלות הנורא בלבד. כן, פ...   \n9   sample14.mp3  הלו? כן, שלום. שלום, אני מתקשרת בקשר למודעה שר...   \n10  sample15.mp3  שלום ותודה שהתקשרתם, ביאבנאנה שלום, מדבר את שו...   \n\n     run_time    engine  text_length                            model  \n0   16.123071  Tesla T4          812  ivrit-ai/whisper-large-v2-tuned  \n1   12.014237  Tesla T4         1047  ivrit-ai/whisper-large-v2-tuned  \n2   20.412798  Tesla T4         1296  ivrit-ai/whisper-large-v2-tuned  \n3    8.944068  Tesla T4          626  ivrit-ai/whisper-large-v2-tuned  \n4    6.888821  Tesla T4          422  ivrit-ai/whisper-large-v2-tuned  \n5   21.519279  Tesla T4         1548  ivrit-ai/whisper-large-v2-tuned  \n6   15.400238  Tesla T4         1113  ivrit-ai/whisper-large-v2-tuned  \n7   27.975692  Tesla T4         1888  ivrit-ai/whisper-large-v2-tuned  \n8    9.820299  Tesla T4          502  ivrit-ai/whisper-large-v2-tuned  \n9   26.842724  Tesla T4         2115  ivrit-ai/whisper-large-v2-tuned  \n10  13.895736  Tesla T4          829  ivrit-ai/whisper-large-v2-tuned  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>text</th>\n      <th>run_time</th>\n      <th>engine</th>\n      <th>text_length</th>\n      <th>model</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>sample1.mp3</td>\n      <td>הלו שלום היי שלום, שנייה הלו שלום הלו, מי אני ...</td>\n      <td>16.123071</td>\n      <td>Tesla T4</td>\n      <td>812</td>\n      <td>ivrit-ai/whisper-large-v2-tuned</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>sample2.mp3</td>\n      <td>היי רותי, רועי מראל, מה הביטוח שלכם, מה שלומך?...</td>\n      <td>12.014237</td>\n      <td>Tesla T4</td>\n      <td>1047</td>\n      <td>ivrit-ai/whisper-large-v2-tuned</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>sample3.mp3</td>\n      <td>שלום, ותודה שתניתם לכולם. מקומכם בתור הינו, אח...</td>\n      <td>20.412798</td>\n      <td>Tesla T4</td>\n      <td>1296</td>\n      <td>ivrit-ai/whisper-large-v2-tuned</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>sample8.mp3</td>\n      <td>הלו, עוזי? כן? חברת טוט, מה קורה? בסדר יופי, מ...</td>\n      <td>8.944068</td>\n      <td>Tesla T4</td>\n      <td>626</td>\n      <td>ivrit-ai/whisper-large-v2-tuned</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>sample9.mp3</td>\n      <td>הלו? שלום. כן, שלום. אני מפרק, מה אתה רואה? אה...</td>\n      <td>6.888821</td>\n      <td>Tesla T4</td>\n      <td>422</td>\n      <td>ivrit-ai/whisper-large-v2-tuned</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>sample10.mp3</td>\n      <td>אבל כן, אבל המהירות גלישה שלנו הרבה יותר גבוהה...</td>\n      <td>21.519279</td>\n      <td>Tesla T4</td>\n      <td>1548</td>\n      <td>ivrit-ai/whisper-large-v2-tuned</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>sample11.mp3</td>\n      <td>שלום אלון, נכון, שלום לך, מדבר את ורד מאיחוד מ...</td>\n      <td>15.400238</td>\n      <td>Tesla T4</td>\n      <td>1113</td>\n      <td>ivrit-ai/whisper-large-v2-tuned</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>sample12.mp3</td>\n      <td>פלקום שלום, תודה על ההמתנה. בוקר טוב. בוקר מצו...</td>\n      <td>27.975692</td>\n      <td>Tesla T4</td>\n      <td>1888</td>\n      <td>ivrit-ai/whisper-large-v2-tuned</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>sample13.mp3</td>\n      <td>בסדרוהחלפת נורא שנשרפה בעלות הנורא בלבד. כן, פ...</td>\n      <td>9.820299</td>\n      <td>Tesla T4</td>\n      <td>502</td>\n      <td>ivrit-ai/whisper-large-v2-tuned</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>sample14.mp3</td>\n      <td>הלו? כן, שלום. שלום, אני מתקשרת בקשר למודעה שר...</td>\n      <td>26.842724</td>\n      <td>Tesla T4</td>\n      <td>2115</td>\n      <td>ivrit-ai/whisper-large-v2-tuned</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>sample15.mp3</td>\n      <td>שלום ותודה שהתקשרתם, ביאבנאנה שלום, מדבר את שו...</td>\n      <td>13.895736</td>\n      <td>Tesla T4</td>\n      <td>829</td>\n      <td>ivrit-ai/whisper-large-v2-tuned</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"results.to_excel('whisper_Transcription.xlsx')","metadata":{"execution":{"iopub.status.busy":"2024-10-23T17:06:19.385024Z","iopub.execute_input":"2024-10-23T17:06:19.385405Z","iopub.status.idle":"2024-10-23T17:06:19.644392Z","shell.execute_reply.started":"2024-10-23T17:06:19.385375Z","shell.execute_reply":"2024-10-23T17:06:19.643658Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"# faster whisper","metadata":{}},{"cell_type":"code","source":"! pip install ffmpeg\n! pip install faster_whisper\nimport ffmpeg\nimport faster_whisper\nimport time\nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2024-10-24T08:54:03.840414Z","iopub.execute_input":"2024-10-24T08:54:03.841305Z","iopub.status.idle":"2024-10-24T08:54:38.136949Z","shell.execute_reply.started":"2024-10-24T08:54:03.841270Z","shell.execute_reply":"2024-10-24T08:54:38.135871Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Collecting ffmpeg\n  Downloading ffmpeg-1.4.tar.gz (5.1 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hBuilding wheels for collected packages: ffmpeg\n  Building wheel for ffmpeg (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for ffmpeg: filename=ffmpeg-1.4-py3-none-any.whl size=6080 sha256=f26cf87ec4549232f31b5c149802b752d000faa2a13f1a404af834dea60a06e7\n  Stored in directory: /root/.cache/pip/wheels/8e/7a/69/cd6aeb83b126a7f04cbe7c9d929028dc52a6e7d525ff56003a\nSuccessfully built ffmpeg\nInstalling collected packages: ffmpeg\nSuccessfully installed ffmpeg-1.4\nCollecting faster_whisper\n  Downloading faster_whisper-1.0.3-py3-none-any.whl.metadata (15 kB)\nCollecting av<13,>=11.0 (from faster_whisper)\n  Downloading av-12.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.6 kB)\nCollecting ctranslate2<5,>=4.0 (from faster_whisper)\n  Downloading ctranslate2-4.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\nRequirement already satisfied: huggingface-hub>=0.13 in /opt/conda/lib/python3.10/site-packages (from faster_whisper) (0.23.2)\nRequirement already satisfied: tokenizers<1,>=0.13 in /opt/conda/lib/python3.10/site-packages (from faster_whisper) (0.19.1)\nCollecting onnxruntime<2,>=1.14 (from faster_whisper)\n  Downloading onnxruntime-1.19.2-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from ctranslate2<5,>=4.0->faster_whisper) (69.0.3)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from ctranslate2<5,>=4.0->faster_whisper) (1.26.4)\nRequirement already satisfied: pyyaml<7,>=5.3 in /opt/conda/lib/python3.10/site-packages (from ctranslate2<5,>=4.0->faster_whisper) (6.0.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.13->faster_whisper) (3.13.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.13->faster_whisper) (2024.3.1)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.13->faster_whisper) (21.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.13->faster_whisper) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.13->faster_whisper) (4.66.4)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.13->faster_whisper) (4.9.0)\nCollecting coloredlogs (from onnxruntime<2,>=1.14->faster_whisper)\n  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: flatbuffers in /opt/conda/lib/python3.10/site-packages (from onnxruntime<2,>=1.14->faster_whisper) (23.5.26)\nRequirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from onnxruntime<2,>=1.14->faster_whisper) (3.20.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from onnxruntime<2,>=1.14->faster_whisper) (1.12.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.13->faster_whisper) (3.1.1)\nCollecting humanfriendly>=9.1 (from coloredlogs->onnxruntime<2,>=1.14->faster_whisper)\n  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.13->faster_whisper) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.13->faster_whisper) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.13->faster_whisper) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.13->faster_whisper) (2024.2.2)\nRequirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->onnxruntime<2,>=1.14->faster_whisper) (1.3.0)\nDownloading faster_whisper-1.0.3-py3-none-any.whl (2.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading av-12.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.5/33.5 MB\u001b[0m \u001b[31m49.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading ctranslate2-4.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.4/38.4 MB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading onnxruntime-1.19.2-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: humanfriendly, ctranslate2, av, coloredlogs, onnxruntime, faster_whisper\nSuccessfully installed av-12.3.0 coloredlogs-15.0.1 ctranslate2-4.5.0 faster_whisper-1.0.3 humanfriendly-10.0 onnxruntime-1.19.2\n","output_type":"stream"}]},{"cell_type":"code","source":"# Initialize the model\nmodel_nm = 'ivrit-ai/faster-whisper-v2-pd1-e1'\nmodel = faster_whisper.WhisperModel(model_nm)","metadata":{"execution":{"iopub.status.busy":"2024-10-24T08:54:38.139028Z","iopub.execute_input":"2024-10-24T08:54:38.140402Z","iopub.status.idle":"2024-10-24T08:55:53.991674Z","shell.execute_reply.started":"2024-10-24T08:54:38.140360Z","shell.execute_reply":"2024-10-24T08:55:53.990066Z"},"trusted":true},"execution_count":29,"outputs":[{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/185k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cc726e574b394a0fbf2fb4cc8a94b4e0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/2.80k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2db438785da242bba366e5d0e338b800"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.48M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b098e5566a249048e295518abd03a9f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocabulary.json:   0%|          | 0.00/1.07M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"048a9e3c5367469da43feab220658901"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.bin:   0%|          | 0.00/3.09G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b410a7cdccb6411596d6904653e2f177"}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[29], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Initialize the model\u001b[39;00m\n\u001b[1;32m      2\u001b[0m model_nm \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mivrit-ai/faster-whisper-v2-pd1-e1\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 3\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mfaster_whisper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWhisperModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_nm\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/faster_whisper/transcribe.py:145\u001b[0m, in \u001b[0;36mWhisperModel.__init__\u001b[0;34m(self, model_size_or_path, device, device_index, compute_type, cpu_threads, num_workers, download_root, local_files_only, files, **model_kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    139\u001b[0m     model_path \u001b[38;5;241m=\u001b[39m download_model(\n\u001b[1;32m    140\u001b[0m         model_size_or_path,\n\u001b[1;32m    141\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[1;32m    142\u001b[0m         cache_dir\u001b[38;5;241m=\u001b[39mdownload_root,\n\u001b[1;32m    143\u001b[0m     )\n\u001b[0;32m--> 145\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43mctranslate2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWhisper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompute_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompute_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m    \u001b[49m\u001b[43mintra_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcpu_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m    \u001b[49m\u001b[43minter_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_workers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    156\u001b[0m tokenizer_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(model_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtokenizer.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tokenizer_bytes:\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA failed with error out of memory"],"ename":"RuntimeError","evalue":"CUDA failed with error out of memory","output_type":"error"}]},{"cell_type":"code","source":"def transcribe_file(file_name):\n    start = time.time()\n    \n    segs, _ = model.transcribe(file_name, language='he')\n    l = []\n    for seg in segs:\n        l.append(seg.text)\n    end = time.time()\n    run_time = end - start\n    \n    return \"\".join(l),run_time","metadata":{"execution":{"iopub.status.busy":"2024-10-24T08:55:53.992386Z","iopub.status.idle":"2024-10-24T08:55:53.992828Z","shell.execute_reply.started":"2024-10-24T08:55:53.992593Z","shell.execute_reply":"2024-10-24T08:55:53.992614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device_name = torch.cuda.get_device_name()","metadata":{"execution":{"iopub.status.busy":"2024-10-24T08:55:53.994822Z","iopub.status.idle":"2024-10-24T08:55:53.995335Z","shell.execute_reply.started":"2024-10-24T08:55:53.995047Z","shell.execute_reply":"2024-10-24T08:55:53.995066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"d = []\nfor i,f in enumerate(audio_files_for_transcribtion):\n    print(i, end='')\n    text,run_time = transcribe_file(files_directory+f)\n    d.append(\n        {\n            'name':f,\n            'text':text,\n            'run_time':run_time,\n            'engine': device_name\n  \n                    }\n    )\n\nresults = pd.DataFrame(d)\nresults","metadata":{"execution":{"iopub.status.busy":"2024-10-24T08:55:53.997350Z","iopub.status.idle":"2024-10-24T08:55:53.997714Z","shell.execute_reply.started":"2024-10-24T08:55:53.997535Z","shell.execute_reply":"2024-10-24T08:55:53.997550Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results['text_length'] = results['text'].str.len()\nresults['model'] = model_nm\nresults","metadata":{"execution":{"iopub.status.busy":"2024-10-24T08:55:54.000022Z","iopub.status.idle":"2024-10-24T08:55:54.000401Z","shell.execute_reply.started":"2024-10-24T08:55:54.000200Z","shell.execute_reply":"2024-10-24T08:55:54.000215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results.to_excel('faster_whisper_Transcription.xlsx')","metadata":{"execution":{"iopub.status.busy":"2024-10-19T15:22:35.271742Z","iopub.execute_input":"2024-10-19T15:22:35.272375Z","iopub.status.idle":"2024-10-19T15:22:35.550811Z","shell.execute_reply.started":"2024-10-19T15:22:35.272342Z","shell.execute_reply":"2024-10-19T15:22:35.549818Z"},"trusted":true},"execution_count":null,"outputs":[]}]}