{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8860713,"sourceType":"datasetVersion","datasetId":5280858}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install auto_gptq -q\n!pip install optimum -q\n!pip install peft -q\n!pip install transformers==4.39.1 -q","metadata":{"execution":{"iopub.status.busy":"2024-07-23T16:52:35.794569Z","iopub.execute_input":"2024-07-23T16:52:35.795526Z","iopub.status.idle":"2024-07-23T16:53:30.733728Z","shell.execute_reply.started":"2024-07-23T16:52:35.795479Z","shell.execute_reply":"2024-07-23T16:53:30.732270Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# import optimum\n# import auto_gptq","metadata":{"execution":{"iopub.status.busy":"2024-07-23T16:53:30.735961Z","iopub.execute_input":"2024-07-23T16:53:30.736301Z","iopub.status.idle":"2024-07-23T16:53:30.740654Z","shell.execute_reply.started":"2024-07-23T16:53:30.736270Z","shell.execute_reply":"2024-07-23T16:53:30.739729Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"!pip install -q -U bitsandbytes\n#!pip install -q -U git+https://github.com/huggingface/transformers.git\n!pip install -q -U git+https://github.com/huggingface/peft.git\n!pip install -q -U git+https://github.com/huggingface/accelerate.git\n!pip install -q datasets\n#!pip install autoawq","metadata":{"execution":{"iopub.status.busy":"2024-07-23T16:53:30.741843Z","iopub.execute_input":"2024-07-23T16:53:30.742182Z","iopub.status.idle":"2024-07-23T16:54:56.992090Z","shell.execute_reply.started":"2024-07-23T16:53:30.742129Z","shell.execute_reply":"2024-07-23T16:54:56.990673Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, pipeline,AutoModelForSeq2SeqLM\nimport torch","metadata":{"execution":{"iopub.status.busy":"2024-07-23T16:54:56.993858Z","iopub.execute_input":"2024-07-23T16:54:56.994259Z","iopub.status.idle":"2024-07-23T16:55:07.169912Z","shell.execute_reply.started":"2024-07-23T16:54:56.994224Z","shell.execute_reply":"2024-07-23T16:55:07.169078Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"2024-07-23 16:55:02.369578: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-07-23 16:55:02.369653: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-07-23 16:55:02.374236: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"# import warnings\n# with warnings.catch_warnings():\n#     warnings.simplefilter(\"ignore\")\n#     df['cat'] = df['item'].apply(categorize_name)\n\n# df.head()","metadata":{"execution":{"iopub.status.busy":"2024-07-23T16:55:07.173311Z","iopub.execute_input":"2024-07-23T16:55:07.174293Z","iopub.status.idle":"2024-07-23T16:55:07.178208Z","shell.execute_reply.started":"2024-07-23T16:55:07.174263Z","shell.execute_reply":"2024-07-23T16:55:07.177108Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# instruct","metadata":{}},{"cell_type":"code","source":"torch.cuda.is_available()","metadata":{"execution":{"iopub.status.busy":"2024-07-23T16:55:07.179437Z","iopub.execute_input":"2024-07-23T16:55:07.179737Z","iopub.status.idle":"2024-07-23T16:55:07.254259Z","shell.execute_reply.started":"2024-07-23T16:55:07.179706Z","shell.execute_reply":"2024-07-23T16:55:07.253430Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, pipeline\n\nif torch.cuda.is_available():\n    model_id = \"dicta-il/dictalm2.0-instruct\"    \n    model = AutoModelForCausalLM.from_pretrained(model_id, device_map=\"cuda\",\n                                                 torch_dtype=torch.bfloat16, low_cpu_mem_usage=True)\n    tokenizer_id = \"dicta-il/dictalm2.0-instruct\"\n    tokenizer = AutoTokenizer.from_pretrained(tokenizer_id)\n    #tokenizer.use_default_system_prompt = False","metadata":{"execution":{"iopub.status.busy":"2024-07-23T16:55:07.255567Z","iopub.execute_input":"2024-07-23T16:55:07.255940Z","iopub.status.idle":"2024-07-23T16:55:53.309712Z","shell.execute_reply.started":"2024-07-23T16:55:07.255906Z","shell.execute_reply":"2024-07-23T16:55:53.308684Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"37643be0a6164d3e9b5542ae15867111"}},"metadata":{}}]},{"cell_type":"code","source":"# from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, pipeline\n# model_name = 'dicta-il/dictalm2.0-instruct'\n\n# device = \"cuda\"\n\n# model = AutoModelForCausalLM.from_pretrained(\"dicta-il/dictalm2.0-instruct\",\n#                                              torch_dtype=torch.bfloat16, device_map=device)\n# tokenizer = AutoTokenizer.from_pretrained(\"dicta-il/dictalm2.0-instruct\")\n\n\n\n# # tokenizer = AutoTokenizer.from_pretrained(model_name)\n\n\n# # model = AutoModelForCausalLM.from_pretrained(model_name,low_cpu_mem_usage=True,\n# #                                              quantization_config = BitsAndBytesConfig(load_in_4bit=True))","metadata":{"execution":{"iopub.status.busy":"2024-07-23T16:55:53.311086Z","iopub.execute_input":"2024-07-23T16:55:53.311869Z","iopub.status.idle":"2024-07-23T16:55:53.316574Z","shell.execute_reply.started":"2024-07-23T16:55:53.311833Z","shell.execute_reply":"2024-07-23T16:55:53.315725Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"torch.backends.cuda.enable_mem_efficient_sdp(False)\ntorch.backends.cuda.enable_flash_sdp(False)","metadata":{"execution":{"iopub.status.busy":"2024-07-23T16:55:53.317873Z","iopub.execute_input":"2024-07-23T16:55:53.318212Z","iopub.status.idle":"2024-07-23T16:55:53.334022Z","shell.execute_reply.started":"2024-07-23T16:55:53.318181Z","shell.execute_reply":"2024-07-23T16:55:53.333006Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"## SENTIMENT","metadata":{}},{"cell_type":"code","source":"%%time\n\ninput_text = \"\"\"\n\nלמה אתם מתקשרים אלי כל הזמן ? \n\"\"\"\n\nprompt = f\"what is the sentiment of the following text : {input_text}\"\nprompt = f\"מה הסנטימנט של הטקטס הבא : {input_text} \"\n\nprompt = f\"\"\"\n\nמה הסנטימנט של הטקטס הבא : {input_text} \n\nבחר מ:\n [+] שלילי.\n [+] חיובי.\nא: [/INST]\n\n\"\"\"\n\n\ninput_ids = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n\noutputs = model.generate(**input_ids,max_new_tokens=50)\nprint(tokenizer.decode(outputs[0]))","metadata":{"execution":{"iopub.status.busy":"2024-07-23T17:39:32.465575Z","iopub.execute_input":"2024-07-23T17:39:32.465935Z","iopub.status.idle":"2024-07-23T17:39:33.241374Z","shell.execute_reply.started":"2024-07-23T17:39:32.465909Z","shell.execute_reply":"2024-07-23T17:39:33.240401Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"<s> \n\nמה הסנטימנט של הטקטס הבא : \n\nלמה אתם מתקשרים אלי כל הזמן ? \n \n\nבחר מ:\n [+] שלילי.\n [+] חיובי.\nא: [/INST]\n\nשלילי.</s>\nCPU times: user 653 ms, sys: 119 ms, total: 771 ms\nWall time: 769 ms\n","output_type":"stream"}]},{"cell_type":"code","source":"input_text = \"\"\"\n\nלמה אתם מתקשרים אלי כל הזמן ? \n\"\"\"\n\ninput_text = \"\"\"\n\nהיי, רותי. רועי מר-אל מהביטוח שלכם. מה שלומך? היי. בסדר. אני גזול דקה וחצי ברשותך 2, עדכון קצר. אנחנו כרגע חוזרים לכולם. זה בסדר? אוקיי. שכוחת קלשיה מבוטחת אצלנו בעצם, שיפרו לכם את התנאים, הוסיפו פיצוי כספי. אני אסביר למה אני מתכוון. את היום בת 30 שתהיה בריאה, נכון? כן. אוקיי. הוסיפו לחשמל 400,000 שקל פיצוי על כל אירוע של תאונת גוף,גם בשעות העבודה, גם עבר לשעות העבודה. זה בעצם על מנת לתת איזשהו ביטחון כלכלי שלא היה לכם עד היום. אנחנו חוזרים אליכם על מנת... כן. מה זה מתחיל, רותי? אתה רוצה... סיפר לי, כאילו... שאלתי, למכור לי משהו, ליישר משהו. כן, כן. בסופו של דבר, אני... מן הסתם, יש עלות, אז בסופו של דבר, אנחנו צריכים את אישורך, זה לא מה שאנחנו עושים על דעת עצמנו. מה זאת אומרת, יש עלות? מה, עלות?אז זהו, אז קודם כול, אני אגיד לך מבחינת מה דאגו לכם, מבחינת הכיסוי. יש לכם השתתפות, אמנם היא גם ירדה משמעותית, אבל עדיין קיימת השתתפות. שוב, אני... אליס, תקשיב. אני... זה לא מעניין. את רוצה לשמוע, רות? את לא חייבת. לא, זה פשוט לא כל כך מעניין מה שעשית. אמרת שאתה מעדכן אותי שאוסיפו משהו. אוסיפו... רותי, את רוצה לשמוע או שלא? לא, אני לא מבינה על מה אנחנו מדברים פשוט.אימא'לה. אימא'לה. אימא'לה. לא מבינה על מה אנחנו מדברים.\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-07-23T17:10:22.445633Z","iopub.execute_input":"2024-07-23T17:10:22.446479Z","iopub.status.idle":"2024-07-23T17:10:22.452770Z","shell.execute_reply.started":"2024-07-23T17:10:22.446444Z","shell.execute_reply":"2024-07-23T17:10:22.451734Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"\n\nheb_template = f\"\"\"[INST] : what is the sentiment of the following text\n: ```{input_text}```\nענה חיובי או שלילי בלבד\n\n[/INST]\n\"\"\"\n\nheb_template = f\"\"\"\n[INST]Analyze the sentiment of the text, \n            determine if it is positive, neutral, or negative, and return the answer as \n            the corresponding sentiment label \"positive\" or \"neutral\" or \"negative\"\n            \n            : ```{input_text}```\n            [/INST]\n\n\"\"\"\n\nheb_template = f\"\"\"\n[INST]\nנתח את הטקסט הבא אשר מתאר שיחה טלפונית בין נציג שירות ולקוח והחזר תשובה האם הסנטימנט של השיחה \n1. חיובי\n2.ניטרלי \n3.שלילי\n            : ```{input_text}```\n            [/INST]\n\n\"\"\"\n\n\n\n\nheb_template = f\"\"\"[INST] : הטקסט הבא מתאר שיחת טלפון בין שני אנשים\n\n?מה הסנטימנט בשיחה\n: ```{input_text}```\n\nאל תפרט, תחזיר תשובה שכוללת רק אחת מהאפשרויות הבאות:\nחיובי,\nשלילי,\nניטרלי,\nלא יודע\n[/INST]\n\"\"\"\n\nheb_template = f\"\"\"[INST] : הטקסט הבא מתאר שיחת טלפון בין שני אנשים\n\n?מה הסנטימנט בשיחה\n: ```{input_text}```\n[/INST]\n\"\"\"\n\n\n\ninput_ids = tokenizer(heb_template, return_tensors=\"pt\").to(\"cuda\")\n\noutputs = model.generate(**input_ids,max_new_tokens=20)\n\nresponse = tokenizer.decode(outputs[0])\nprint(response)","metadata":{"execution":{"iopub.status.busy":"2024-07-23T17:19:42.183958Z","iopub.execute_input":"2024-07-23T17:19:42.184647Z","iopub.status.idle":"2024-07-23T17:19:46.954664Z","shell.execute_reply.started":"2024-07-23T17:19:42.184606Z","shell.execute_reply":"2024-07-23T17:19:46.953691Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"<s> [INST] : הטקסט הבא מתאר שיחת טלפון בין שני אנשים\n\n?מה הסנטימנט בשיחה\n: ```\n\nהיי, רותי. רועי מר-אל מהביטוח שלכם. מה שלומך? היי. בסדר. אני גזול דקה וחצי ברשותך 2, עדכון קצר. אנחנו כרגע חוזרים לכולם. זה בסדר? אוקיי. שכוחת קלשיה מבוטחת אצלנו בעצם, שיפרו לכם את התנאים, הוסיפו פיצוי כספי. אני אסביר למה אני מתכוון. את היום בת 30 שתהיה בריאה, נכון? כן. אוקיי. הוסיפו לחשמל 400,000 שקל פיצוי על כל אירוע של תאונת גוף,גם בשעות העבודה, גם עבר לשעות העבודה. זה בעצם על מנת לתת איזשהו ביטחון כלכלי שלא היה לכם עד היום. אנחנו חוזרים אליכם על מנת... כן. מה זה מתחיל, רותי? אתה רוצה... סיפר לי, כאילו... שאלתי, למכור לי משהו, ליישר משהו. כן, כן. בסופו של דבר, אני... מן הסתם, יש עלות, אז בסופו של דבר, אנחנו צריכים את אישורך, זה לא מה שאנחנו עושים על דעת עצמנו. מה זאת אומרת, יש עלות? מה, עלות?אז זהו, אז קודם כול, אני אגיד לך מבחינת מה דאגו לכם, מבחינת הכיסוי. יש לכם השתתפות, אמנם היא גם ירדה משמעותית, אבל עדיין קיימת השתתפות. שוב, אני... אליס, תקשיב. אני... זה לא מעניין. את רוצה לשמוע, רות? את לא חייבת. לא, זה פשוט לא כל כך מעניין מה שעשית. אמרת שאתה מעדכן אותי שאוסיפו משהו. אוסיפו... רותי, את רוצה לשמוע או שלא? לא, אני לא מבינה על מה אנחנו מדברים פשוט.אימא'לה. אימא'לה. אימא'לה. לא מבינה על מה אנחנו מדברים.\n```\n[/INST]\nהשיחה היא בעלת רגש שלילי. היא מתחילה עם שאלות מנ\n","output_type":"stream"}]},{"cell_type":"code","source":"def get_sentiment(row, full_response=False):\n\n    try:\n\n        heb_template = f\"\"\"[INST] : הטקסט הבא מתאר שיחת טלפון בין שני אנשים\n\n        ?מה הסנטימנט בשיחה\n        : ```{row}```\n        [/INST]\n        \"\"\"\n\n        input_ids = tokenizer(heb_template, return_tensors=\"pt\").to(\"cuda\")\n\n        outputs = model.generate(**input_ids, max_new_tokens=100,\n                                temperature=0.99,\n                                pad_token_id=tokenizer.eos_token_id,\n                               do_sample=True\n                                )\n\n        response = tokenizer.decode(outputs[0])\n        response = response.split('[/INST]')[1]\n\n        if not full_response:\n            if 'שלילי' in response:\n                response = 'שלילי'\n            if 'חיובי' in response:\n                response = 'חיובי'\n            else:\n                response = 'אחר'\n\n    except:\n\n        response = 'generation error'\n\n    return response\n","metadata":{"execution":{"iopub.status.busy":"2024-07-23T17:37:34.127717Z","iopub.execute_input":"2024-07-23T17:37:34.128407Z","iopub.status.idle":"2024-07-23T17:37:34.135505Z","shell.execute_reply.started":"2024-07-23T17:37:34.128362Z","shell.execute_reply":"2024-07-23T17:37:34.134683Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":"## SUMMARY","metadata":{}},{"cell_type":"code","source":"heb_template = f\"\"\"[INST] : הטקסט הבא מתאר שיחת טלפון בין שני אנשים סכם את השיחה בקצרה,\n                            התייחס למטרת השיחה, מי התקשר ואל מי,\n                            תוצאת השיחה והסנטימנט הכללי בשיחה\n                            אל תרחיב יותר מידי, סכם את עיקרי הדברים\n\n                            : ```{input_text}```\n\n                            [/INST]\n\"\"\"\ninput_ids = tokenizer(heb_template, return_tensors=\"pt\").to(\"cuda\")\n\noutputs = model.generate(**input_ids,max_new_tokens=100,\n                        temperature=0.99,\n                         do_sample=True)\n\nresponse = tokenizer.decode(outputs[0])\nprint(response)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_excel('/kaggle/input/speech-to-text/T4bench.xlsx',index_col=[0])\ndf = df.head(4)","metadata":{"execution":{"iopub.status.busy":"2024-07-23T16:55:53.335300Z","iopub.execute_input":"2024-07-23T16:55:53.335919Z","iopub.status.idle":"2024-07-23T16:55:53.476899Z","shell.execute_reply.started":"2024-07-23T16:55:53.335885Z","shell.execute_reply":"2024-07-23T16:55:53.476077Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def get_summary(row):\n    \n    try:\n    \n        heb_template = f\"\"\"[INST] : הטקסט הבא מתאר שיחת טלפון בין שני אנשים סכם את השיחה בקצרה, התייחס למטרת השיחה, מי התקשר ואל מי\n        , \n        תוצאת השיחה והסנטימנט הכללי בשיחה\n        אל תרחיב יותר מידי, סכם את עיקרי הדברים\n\n        : ```{row}```\n\n\n        [/INST]\n        \"\"\"\n        input_ids = tokenizer(heb_template, return_tensors=\"pt\").to(\"cuda\")\n\n        outputs = model.generate(**input_ids,max_new_tokens=100,\n                              #  temperature=0.99,\n                              #   do_sample=True\n                                 pad_token_id=tokenizer.eos_token_id\n                                )\n\n        response = tokenizer.decode(outputs[0])\n        \n    except:\n        \n        response = '[/INST]generation error'\n\n    return response.split('[/INST]')[1]","metadata":{"execution":{"iopub.status.busy":"2024-07-23T16:55:53.478183Z","iopub.execute_input":"2024-07-23T16:55:53.478826Z","iopub.status.idle":"2024-07-23T16:55:53.486995Z","shell.execute_reply.started":"2024-07-23T16:55:53.478784Z","shell.execute_reply":"2024-07-23T16:55:53.485917Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ndf['summary'] = df['text'].apply(get_summary)","metadata":{"execution":{"iopub.status.busy":"2024-07-23T16:55:53.488082Z","iopub.execute_input":"2024-07-23T16:55:53.488438Z","iopub.status.idle":"2024-07-23T16:56:36.704500Z","shell.execute_reply.started":"2024-07-23T16:55:53.488405Z","shell.execute_reply":"2024-07-23T16:56:36.703502Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"CPU times: user 40.6 s, sys: 2.63 s, total: 43.2 s\nWall time: 43.2 s\n","output_type":"stream"}]},{"cell_type":"code","source":"%%time\ndf['sentiment'] = df['text'].apply(get_sentiment,args=(True ,))","metadata":{"execution":{"iopub.status.busy":"2024-07-23T17:38:18.160947Z","iopub.execute_input":"2024-07-23T17:38:18.161704Z","iopub.status.idle":"2024-07-23T17:39:00.811001Z","shell.execute_reply.started":"2024-07-23T17:38:18.161670Z","shell.execute_reply":"2024-07-23T17:39:00.809949Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":"CPU times: user 39.8 s, sys: 2.75 s, total: 42.6 s\nWall time: 42.6 s\n","output_type":"stream"}]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-07-23T17:39:00.812609Z","iopub.execute_input":"2024-07-23T17:39:00.812955Z","iopub.status.idle":"2024-07-23T17:39:00.827229Z","shell.execute_reply.started":"2024-07-23T17:39:00.812928Z","shell.execute_reply":"2024-07-23T17:39:00.826090Z"},"trusted":true},"execution_count":44,"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"                                       name  \\\n0  /kaggle/input/speech-to-text/sample1.mp3   \n1  /kaggle/input/speech-to-text/sample2.mp3   \n2  /kaggle/input/speech-to-text/sample3.mp3   \n3  /kaggle/input/speech-to-text/sample4.mp3   \n\n                                                text   run_time engine  \\\n0  אנא הג'נד, סופר. יפה מאוד, יפה מאוד. עוד עליך,...  31.665811    cpu   \n1  היי, רותי. רועי מר-אל מהביטוח שלכם. מה שלומך? ...  16.178251    cpu   \n2  שלום. ותודה שאת ניתן לקרוא. מקומכם בתור הינו, ...  19.817106    cpu   \n3  זו חברת הוט גלעד, אני יודע שאתה לא אוהב אותנו ...  18.442701    cpu   \n\n                                             summary  \\\n0  \\n        \\nמטרת השיחה היא לפתור בעיה של מהירו...   \n1  \\n        רות קיבלה שיחה מרועי, נציג הביטוח של...   \n2  \\n        \\nמטרת השיחה היא לפתור בעיה עם מוצר ...   \n3  \\n        גלעד התקשר לחברת הוט כדי לדון בעזיבת...   \n\n                                           sentiment  \n0  \\n        ❎ שלילי, או שזה שלילי במיוחד.\\n\\nהטו...  \n1  \\n        רגשית, השיחה נראית חווייתית, נלהבת ו...  \n2  \\n        \\nסנטימנט מתוסכל ועוין בשיחת הטלפון....  \n3  \\n        \\n  הביטוי הרגשי או המצב רוח בשיחה ה...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>text</th>\n      <th>run_time</th>\n      <th>engine</th>\n      <th>summary</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>/kaggle/input/speech-to-text/sample1.mp3</td>\n      <td>אנא הג'נד, סופר. יפה מאוד, יפה מאוד. עוד עליך,...</td>\n      <td>31.665811</td>\n      <td>cpu</td>\n      <td>\\n        \\nמטרת השיחה היא לפתור בעיה של מהירו...</td>\n      <td>\\n        ❎ שלילי, או שזה שלילי במיוחד.\\n\\nהטו...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>/kaggle/input/speech-to-text/sample2.mp3</td>\n      <td>היי, רותי. רועי מר-אל מהביטוח שלכם. מה שלומך? ...</td>\n      <td>16.178251</td>\n      <td>cpu</td>\n      <td>\\n        רות קיבלה שיחה מרועי, נציג הביטוח של...</td>\n      <td>\\n        רגשית, השיחה נראית חווייתית, נלהבת ו...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>/kaggle/input/speech-to-text/sample3.mp3</td>\n      <td>שלום. ותודה שאת ניתן לקרוא. מקומכם בתור הינו, ...</td>\n      <td>19.817106</td>\n      <td>cpu</td>\n      <td>\\n        \\nמטרת השיחה היא לפתור בעיה עם מוצר ...</td>\n      <td>\\n        \\nסנטימנט מתוסכל ועוין בשיחת הטלפון....</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>/kaggle/input/speech-to-text/sample4.mp3</td>\n      <td>זו חברת הוט גלעד, אני יודע שאתה לא אוהב אותנו ...</td>\n      <td>18.442701</td>\n      <td>cpu</td>\n      <td>\\n        גלעד התקשר לחברת הוט כדי לדון בעזיבת...</td>\n      <td>\\n        \\n  הביטוי הרגשי או המצב רוח בשיחה ה...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"eng_template = f\"\"\"[INST] For the following text of a phone call, extract the following information:\n\ncaller : who is the caller\n\nsubject: what is the reason of the call\n\nsentiment: what is the sentiment in the conversation\n\nThe text is: ```{input_text}```\n\nreturn answer as list [caller,subject,sentiment] \n\n\n\n[/INST]\n\"\"\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"template = f\"\"\"[INST] For the following text of a phone call, extract the following information:\n\ncaller : who is the caller\n\nsubject: what is the reason of the call\n\nsentiment: what is the sentiment in the conversation\n\nThe texs is: ```{input_text}```\n\nreturn answer in dictionary format and in hebrew\n\n\n\n[/INST]\n\"\"\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install qrcode","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import qrcode\nimg = qrcode.make('בובו')\nimg","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}